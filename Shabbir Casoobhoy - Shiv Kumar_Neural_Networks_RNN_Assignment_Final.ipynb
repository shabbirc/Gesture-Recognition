{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    temp = imresize(image,(120,120))\n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (temp[:,:,0]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (temp[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (temp[:,:,2]) #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    temp = imresize(image,(120,120))\n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (temp[:,:,0])\n",
    "                    batch_data[folder,idx,:,:,1] = (temp[:,:,1])\n",
    "                    batch_data[folder,idx,:,:,2] = (temp[:,:,2])\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "#write your model here\n",
    "#model a\n",
    "model_a = Sequential()\n",
    "\n",
    "model_a.add(Conv3D(8, #number of filters \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=(30, 120, 120, 3),\n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_a.add(Conv3D(16, #Number of filters, \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_a.add(Conv3D(32, #Number of filters \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_a.add(Conv3D(64, #Number pf filters \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_a.add(Flatten())\n",
    "\n",
    "model_a.add(Dense(1000, activation='relu'))\n",
    "model_a.add(Dropout(0.5))\n",
    "\n",
    "model_a.add(Dense(500, activation='relu'))\n",
    "model_a.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_a.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(lr=0.001) #write your optimizer\n",
    "model_a.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_a.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 5s - loss: 4.4560 - categorical_accuracy: 0.3092Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 172s 3s/step - loss: 4.4106 - categorical_accuracy: 0.3065 - val_loss: 1.7334 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-4.44667-0.30618-1.73339-0.45000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 2.5737 - categorical_accuracy: 0.3184 - val_loss: 1.4163 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-2.57374-0.31841-1.41633-0.39000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 27s 396ms/step - loss: 1.9961 - categorical_accuracy: 0.2836 - val_loss: 1.2224 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.99614-0.28358-1.22240-0.45000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 1.6165 - categorical_accuracy: 0.2836 - val_loss: 1.2812 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.61655-0.28358-1.28119-0.54000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 1.4995 - categorical_accuracy: 0.3582 - val_loss: 1.2312 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.49951-0.35821-1.23123-0.50000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 28s 411ms/step - loss: 1.4976 - categorical_accuracy: 0.3333 - val_loss: 1.1903 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.49765-0.33333-1.19028-0.53000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 1.3499 - categorical_accuracy: 0.4179 - val_loss: 1.2797 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.34992-0.41791-1.27973-0.45000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 1.3442 - categorical_accuracy: 0.4428 - val_loss: 1.1650 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.34417-0.44279-1.16499-0.59000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 1.2552 - categorical_accuracy: 0.4378 - val_loss: 1.0914 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.25517-0.43781-1.09143-0.54000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 26s 393ms/step - loss: 1.2563 - categorical_accuracy: 0.4726 - val_loss: 1.1196 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.25633-0.47264-1.11956-0.63000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c199a1128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 5 #left swipe, right swipe, thumbs up, thumbs down, stop\n",
    "channel = 3\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n",
    "\n",
    "def generator_ex(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,channel)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    temp = imresize(image,(y,z))\n",
    "                    #Converting to gray scale\n",
    "                    temp = temp.mean(axis=-1,keepdims=1) \n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    batch_data[folder,idx] = temp #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                \n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,channel)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    temp = imresize(image,(y,z))\n",
    "                    #Converting to gray scale\n",
    "                    temp = temp.mean(axis=-1,keepdims=1) \n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx] = temp\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 30, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 30, 120, 120, 32)  27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 10, 40, 40, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 40, 40, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 10, 40, 40, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10, 40, 40, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               25690624  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 25,889,509\n",
      "Trainable params: 25,889,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define model b\n",
    "model_b = Sequential()\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Flatten())\n",
    "model_b.add(Dense(512, activation='relu'))\n",
    "model_b.add(Dropout(0.5))\n",
    "model_b.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model_b.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/67 [========================>.....] - ETA: 21s - loss: 1.8214 - categorical_accuracy: 0.1786Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 136s 2s/step - loss: 1.7866 - categorical_accuracy: 0.1915 - val_loss: 1.6091 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-1.78850-0.19005-1.60908-0.21000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.6085 - categorical_accuracy: 0.1891 - val_loss: 1.6084 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-1.60854-0.18905-1.60837-0.21000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 48s 716ms/step - loss: 1.6131 - categorical_accuracy: 0.1841 - val_loss: 1.6077 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.61307-0.18408-1.60770-0.21000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.6099 - categorical_accuracy: 0.2189 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.60986-0.21891-1.60805-0.21000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 48s 716ms/step - loss: 1.6063 - categorical_accuracy: 0.2687 - val_loss: 1.6073 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.60634-0.26866-1.60730-0.21000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 48s 716ms/step - loss: 1.6108 - categorical_accuracy: 0.1891 - val_loss: 1.6074 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.61085-0.18905-1.60736-0.21000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.6101 - categorical_accuracy: 0.1940 - val_loss: 1.6075 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.61007-0.19403-1.60748-0.21000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.6102 - categorical_accuracy: 0.1791 - val_loss: 1.6076 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.61024-0.17910-1.60760-0.21000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.6108 - categorical_accuracy: 0.2090 - val_loss: 1.6079 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.61079-0.20896-1.60792-0.21000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.6084 - categorical_accuracy: 0.1692 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.60843-0.16915-1.60797-0.21000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b7004db70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing x,y,z values Experiment [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # number of frames\n",
    "y = 60 # image width\n",
    "z = 60 # image height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model b\n",
    "model_b = Sequential()\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Flatten())\n",
    "model_b.add(Dense(512, activation='relu'))\n",
    "model_b.add(Dropout(0.5))\n",
    "model_b.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model_b.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 1.5863 - categorical_accuracy: 0.2446Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 73s 1s/step - loss: 1.5829 - categorical_accuracy: 0.2472 - val_loss: 1.4636 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-1.58540-0.24284-1.46360-0.26000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 1.4767 - categorical_accuracy: 0.3682 - val_loss: 1.4569 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-1.47666-0.36816-1.45693-0.42000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 1.5003 - categorical_accuracy: 0.3383 - val_loss: 1.3762 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.50025-0.33831-1.37623-0.35000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 24s 357ms/step - loss: 1.4387 - categorical_accuracy: 0.3980 - val_loss: 1.4849 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.43870-0.39801-1.48495-0.40000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 1.3605 - categorical_accuracy: 0.4229 - val_loss: 1.3776 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.36051-0.42289-1.37764-0.40000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 24s 363ms/step - loss: 1.2907 - categorical_accuracy: 0.4179 - val_loss: 1.3463 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.29069-0.41791-1.34631-0.43000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 25s 366ms/step - loss: 1.2861 - categorical_accuracy: 0.4229 - val_loss: 1.2188 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.28611-0.42289-1.21885-0.47000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 1.1688 - categorical_accuracy: 0.4975 - val_loss: 1.1330 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.16879-0.49751-1.13302-0.53000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 25s 367ms/step - loss: 1.0782 - categorical_accuracy: 0.5522 - val_loss: 1.1615 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.07823-0.55224-1.16154-0.47000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 24s 361ms/step - loss: 1.0750 - categorical_accuracy: 0.4726 - val_loss: 1.1142 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.07504-0.47264-1.11421-0.53000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b7021d0f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Batch size to 20 Experiment [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 20)\n",
    "val_generator = generator_ex(val_path, val_doc, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 20Source path =  Project_data/train ; batch size = 20\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/67 [=============>................] - ETA: 1:19 - loss: 0.9578 - categorical_accuracy: 0.5906Batch:  34 Index: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 87s 1s/step - loss: 0.9117 - categorical_accuracy: 0.6282 - val_loss: 1.0566 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.94848-0.59974-1.05664-0.55000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 28s 425ms/step - loss: 0.9651 - categorical_accuracy: 0.5771 - val_loss: 1.0996 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.96505-0.57711-1.09957-0.52000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 30s 453ms/step - loss: 0.9546 - categorical_accuracy: 0.6169 - val_loss: 1.0643 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.95462-0.61692-1.06425-0.52000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 30s 451ms/step - loss: 0.8757 - categorical_accuracy: 0.6119 - val_loss: 0.9274 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.87566-0.61194-0.92736-0.63000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 30s 450ms/step - loss: 0.7090 - categorical_accuracy: 0.7164 - val_loss: 0.9397 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.70899-0.71642-0.93971-0.66000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 30s 449ms/step - loss: 0.6600 - categorical_accuracy: 0.7363 - val_loss: 0.8965 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.65996-0.73632-0.89645-0.62000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 30s 446ms/step - loss: 0.7413 - categorical_accuracy: 0.6418 - val_loss: 0.9081 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.74134-0.64179-0.90810-0.63000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 30s 443ms/step - loss: 0.6661 - categorical_accuracy: 0.7214 - val_loss: 0.8820 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.66611-0.72139-0.88196-0.62000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 30s 450ms/step - loss: 0.6174 - categorical_accuracy: 0.7413 - val_loss: 0.9502 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.61738-0.74129-0.95019-0.59000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 30s 448ms/step - loss: 0.6999 - categorical_accuracy: 0.7114 - val_loss: 1.1185 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.69988-0.71144-1.11852-0.59000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bb4030198>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Batch size to 30 Experiment [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 30)\n",
    "val_generator = generator_ex(val_path, val_doc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/trainEpoch 1/10\n",
      " ; batch size = 30\n",
      " Project_data/val ; batch size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/67 [>.............................] - ETA: 4:57 - loss: 0.6738 - categorical_accuracy: 0.7444Batch:  4 Index: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/67 [========>.....................] - ETA: 2:35 - loss: 0.5476 - categorical_accuracy: 0.8000Batch:  23 Index: 30\n",
      "67/67 [==============================] - 88s 1s/step - loss: 0.5762 - categorical_accuracy: 0.7920 - val_loss: 0.9627 - val_categorical_accuracy: 0.6313\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.56468-0.79119-0.96271-0.63125.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 25s 369ms/step - loss: 0.5015 - categorical_accuracy: 0.8060 - val_loss: 0.9279 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.50150-0.80597-0.92789-0.61000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 24s 364ms/step - loss: 0.4823 - categorical_accuracy: 0.8109 - val_loss: 0.8731 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.48229-0.81095-0.87311-0.66000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 23s 348ms/step - loss: 0.4339 - categorical_accuracy: 0.8259 - val_loss: 0.8381 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.43393-0.82587-0.83806-0.67000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 0.4246 - categorical_accuracy: 0.8358 - val_loss: 1.0235 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.42463-0.83582-1.02350-0.55000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 0.4438 - categorical_accuracy: 0.8259 - val_loss: 0.8056 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.44380-0.82587-0.80563-0.69000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 0.3854 - categorical_accuracy: 0.8607 - val_loss: 1.0035 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.38544-0.86070-1.00348-0.63000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 25s 371ms/step - loss: 0.3812 - categorical_accuracy: 0.8557 - val_loss: 0.9482 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.38123-0.85572-0.94816-0.63000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 0.2961 - categorical_accuracy: 0.9104 - val_loss: 1.0305 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.29611-0.91045-1.03046-0.62000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.3048 - categorical_accuracy: 0.8756 - val_loss: 0.9074 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.30478-0.87562-0.90742-0.67000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bb4030e10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Batch size to 40 Experiment [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 40)\n",
    "val_generator = generator_ex(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Source path =  Project_data/train ; batch size = 40\n",
      "Project_data/val ; batch size = 40\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/67 [..............................] - ETA: 11:26 - loss: 0.3630 - categorical_accuracy: 0.8250Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/67 [=====>........................] - ETA: 4:03 - loss: 0.2914 - categorical_accuracy: 0.8883Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:13 - loss: 0.2941 - categorical_accuracy: 0.8885Batch:  29 Index: 23\n",
      "67/67 [==============================] - 187s 3s/step - loss: 0.3007 - categorical_accuracy: 0.8879 - val_loss: 0.9434 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.29789-0.88812-0.94339-0.66667.h5\n",
      "Epoch 2/10\n",
      "12/67 [====>.........................] - ETA: 2:03 - loss: 0.2619 - categorical_accuracy: 0.9123Batch:  35 Index: 19\n",
      "67/67 [==============================] - 127s 2s/step - loss: 0.2865 - categorical_accuracy: 0.9002 - val_loss: 0.9878 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.28591-0.90043-0.98776-0.62500.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.2837 - categorical_accuracy: 0.8999 - val_loss: 0.9866 - val_categorical_accuracy: 0.6550\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.28374-0.89991-0.98658-0.65500.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.2597 - categorical_accuracy: 0.9078 - val_loss: 0.9741 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.25970-0.90781-0.97408-0.63000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.2904 - categorical_accuracy: 0.8938 - val_loss: 1.0474 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.29045-0.89377-1.04736-0.64000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.2651 - categorical_accuracy: 0.9140 - val_loss: 1.0063 - val_categorical_accuracy: 0.6350\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.26511-0.91396-1.00632-0.63500.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.2515 - categorical_accuracy: 0.9061 - val_loss: 0.9855 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.25152-0.90606-0.98546-0.65000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.2433 - categorical_accuracy: 0.9183 - val_loss: 0.9374 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.24335-0.91835-0.93739-0.62500.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.2440 - categorical_accuracy: 0.9131 - val_loss: 1.0463 - val_categorical_accuracy: 0.6350\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.24396-0.91308-1.04628-0.63500.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.2735 - categorical_accuracy: 0.9052 - val_loss: 1.0174 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.27353-0.90518-1.01738-0.66000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bb407ee10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Optimizer to Adadelta Experiment [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_b.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 40)\n",
    "val_generator = generator_ex(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Epoch 1/10Project_data/train ; batch size = 40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/67 [..............................] - ETA: 5:39 - loss: 0.2641 - categorical_accuracy: 0.9000Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/67 [=====>........................] - ETA: 4:01 - loss: 0.3781 - categorical_accuracy: 0.8483Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:12 - loss: 0.3767 - categorical_accuracy: 0.8447Batch:  29 Index: 23\n",
      "67/67 [==============================] - 189s 3s/step - loss: 0.3501 - categorical_accuracy: 0.8636 - val_loss: 1.4383 - val_categorical_accuracy: 0.6042\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.35603-0.85971-1.43828-0.60417.h5\n",
      "Epoch 2/10\n",
      "12/67 [====>.........................] - ETA: 1:50 - loss: 0.2661 - categorical_accuracy: 0.8991Batch:  35 Index: 19\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.2760 - categorical_accuracy: 0.9035 - val_loss: 1.0144 - val_categorical_accuracy: 0.6650\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.27642-0.90300-1.01438-0.66500.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.1802 - categorical_accuracy: 0.9342 - val_loss: 1.7026 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.18024-0.93415-1.70264-0.62500.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.1708 - categorical_accuracy: 0.9438 - val_loss: 1.4130 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.17084-0.94381-1.41301-0.68000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0864 - categorical_accuracy: 0.9701 - val_loss: 1.6186 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.08645-0.97015-1.61855-0.65000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0758 - categorical_accuracy: 0.9781 - val_loss: 1.4767 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.07581-0.97805-1.47673-0.66000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0454 - categorical_accuracy: 0.9868 - val_loss: 1.6350 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.04540-0.98683-1.63502-0.63000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0419 - categorical_accuracy: 0.9860 - val_loss: 1.7154 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.04188-0.98595-1.71543-0.69000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.0478 - categorical_accuracy: 0.9816 - val_loss: 1.4305 - val_categorical_accuracy: 0.6650\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.04781-0.98156-1.43050-0.66500.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0339 - categorical_accuracy: 0.9895 - val_loss: 1.7755 - val_categorical_accuracy: 0.6550\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.03391-0.98946-1.77546-0.65500.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0625.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba7183160>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change epoch to 20 Experiment [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "model_b.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 40)\n",
    "val_generator = generator_ex(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Epoch 1/20\n",
      "Project_data/train ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/67 [..............................] - ETA: 6:00 - loss: 0.0219 - categorical_accuracy: 1.0000Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/67 [=====>........................] - ETA: 3:58 - loss: 0.2095 - categorical_accuracy: 0.9550Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:11 - loss: 0.1264 - categorical_accuracy: 0.9638Batch:  29 Index: 23\n",
      "67/67 [==============================] - 184s 3s/step - loss: 0.1303 - categorical_accuracy: 0.9591 - val_loss: 1.9376 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.14102-0.95884-1.93762-0.63333.h5\n",
      "Epoch 2/20\n",
      "12/67 [====>.........................] - ETA: 1:59 - loss: 0.0498 - categorical_accuracy: 0.9825Batch:  35 Index: 19\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0729 - categorical_accuracy: 0.9749 - val_loss: 1.3213 - val_categorical_accuracy: 0.7450\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.07235-0.97511-1.32130-0.74500.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0507 - categorical_accuracy: 0.9842 - val_loss: 2.0168 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.05070-0.98420-2.01679-0.69000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0408 - categorical_accuracy: 0.9886 - val_loss: 2.1468 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.04078-0.98859-2.14683-0.67500.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0300 - categorical_accuracy: 0.9895 - val_loss: 2.1497 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.02995-0.98946-2.14967-0.64000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0148 - categorical_accuracy: 0.9947 - val_loss: 1.9327 - val_categorical_accuracy: 0.7350\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.01480-0.99473-1.93274-0.73500.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0187 - categorical_accuracy: 0.9930 - val_loss: 2.2992 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.01872-0.99298-2.29916-0.65000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0199 - categorical_accuracy: 0.9930 - val_loss: 2.3220 - val_categorical_accuracy: 0.6650\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.01993-0.99298-2.32203-0.66500.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.0154 - categorical_accuracy: 0.9956 - val_loss: 2.0873 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.01535-0.99561-2.08730-0.68000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.0079 - categorical_accuracy: 0.9991 - val_loss: 2.2178 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.00785-0.99912-2.21776-0.66000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0073 - categorical_accuracy: 0.9991 - val_loss: 2.0951 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-0.00732-0.99912-2.09506-0.67500.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0138 - categorical_accuracy: 0.9930 - val_loss: 2.3663 - val_categorical_accuracy: 0.6450\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-0.01375-0.99298-2.36629-0.64500.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.03125.\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0041 - categorical_accuracy: 0.9991 - val_loss: 2.1500 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-0.00408-0.99912-2.14998-0.67500.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.0052 - categorical_accuracy: 0.9991 - val_loss: 2.3670 - val_categorical_accuracy: 0.6650\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-0.00525-0.99912-2.36705-0.66500.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.015625.\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0081 - categorical_accuracy: 0.9974 - val_loss: 2.1935 - val_categorical_accuracy: 0.6550\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-0.00806-0.99737-2.19351-0.65500.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0129 - categorical_accuracy: 0.9965 - val_loss: 2.1983 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-0.01294-0.99649-2.19827-0.67000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0078125.\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.0099 - categorical_accuracy: 0.9974 - val_loss: 2.3187 - val_categorical_accuracy: 0.6950\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-0.00989-0.99737-2.31869-0.69500.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0154 - categorical_accuracy: 0.9947 - val_loss: 1.9411 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-0.01541-0.99473-1.94114-0.67500.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00390625.\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0100 - categorical_accuracy: 0.9974 - val_loss: 2.3391 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-0.00999-0.99737-2.33907-0.66000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.0095 - categorical_accuracy: 0.9965 - val_loss: 2.0887 - val_categorical_accuracy: 0.6850\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-0.00954-0.99649-2.08868-0.68500.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.001953125.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba7189240>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Till this point we achieved 99.39% accuracy in training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model D Experiment [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_19 (Conv3D)           (None, 30, 60, 60, 8)     656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 60, 60, 8)     32        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 30, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 15, 30, 30, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 15, 30, 30, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 30, 30, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 15, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 7, 15, 15, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 7, 15, 15, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 15, 15, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 3, 7, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 3, 7, 7, 64)       18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 7, 7, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 1, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              577000    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 1,107,749\n",
      "Trainable params: 1,107,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "# Define model\n",
    "model_d = Sequential()\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_d.add(Flatten())\n",
    "\n",
    "model_d.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "\n",
    "model_d.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_d.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_d.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 2.0893 - categorical_accuracy: 0.2877Batch:  67 Index: 10\n",
      "66/67 [============================>.] - ETA: 1s - loss: 2.0798 - categorical_accuracy: 0.2879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 71s 1s/step - loss: 2.0780 - categorical_accuracy: 0.2886 - val_loss: 1.6151 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-2.07930-0.28808-1.61512-0.31000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 22s 326ms/step - loss: 1.8124 - categorical_accuracy: 0.2886 - val_loss: 1.3198 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-1.81239-0.28856-1.31977-0.47000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 23s 350ms/step - loss: 1.5449 - categorical_accuracy: 0.3433 - val_loss: 1.0643 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.54486-0.34328-1.06427-0.55000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 23s 345ms/step - loss: 1.5489 - categorical_accuracy: 0.3433 - val_loss: 1.2111 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.54886-0.34328-1.21112-0.53000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 1.3843 - categorical_accuracy: 0.4478 - val_loss: 1.7491 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.38431-0.44776-1.74910-0.36000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 22s 330ms/step - loss: 1.3175 - categorical_accuracy: 0.4080 - val_loss: 1.0135 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.31747-0.40796-1.01352-0.55000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 24s 353ms/step - loss: 1.1955 - categorical_accuracy: 0.4925 - val_loss: 1.0256 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.19551-0.49254-1.02563-0.51000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 23s 343ms/step - loss: 1.2625 - categorical_accuracy: 0.4677 - val_loss: 0.9572 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.26247-0.46766-0.95716-0.60000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 1.1922 - categorical_accuracy: 0.5224 - val_loss: 1.0250 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.19222-0.52239-1.02502-0.54000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 24s 356ms/step - loss: 1.2257 - categorical_accuracy: 0.4527 - val_loss: 0.8782 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.22566-0.45274-0.87821-0.68000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba021beb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_d.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Model with images per frame, width and height of the images Experiment [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # number of frames\n",
    "y = 64 # image width\n",
    "z = 64 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_23 (Conv3D)           (None, 30, 64, 64, 32)    896       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 30, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 30, 64, 64, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 30, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 10, 22, 22, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10, 22, 22, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 10, 22, 22, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10, 22, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 10, 22, 22, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10, 22, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 4, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 4, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,010,853\n",
      "Trainable params: 1,009,829\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_e = Sequential()\n",
    "model_e.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding=\"same\"))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_e.add(Dropout(0.25))\n",
    "\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_e.add(Dropout(0.25))\n",
    "\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_e.add(Dropout(0.25))\n",
    "\n",
    "model_e.add(Flatten())\n",
    "model_e.add(Dense(512, activation='relu'))\n",
    "model_e.add(BatchNormalization())\n",
    "model_e.add(Dropout(0.5))\n",
    "model_e.add(Dense(classes, activation='softmax'))\n",
    "model_e.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 5\n",
      "Source path =  Project_data/train ; batch size = 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 38s 561ms/step - loss: 2.3012 - categorical_accuracy: 0.2328 - val_loss: 2.5908 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-2.30120-0.23284-2.59084-0.30000.h5\n",
      "Epoch 2/20\n",
      "64/67 [===========================>..] - ETA: 1s - loss: 2.1346 - categorical_accuracy: 0.2500Batch:  133 Index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 35s 525ms/step - loss: 2.1378 - categorical_accuracy: 0.2478 - val_loss: 2.3255 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-2.13216-0.25076-2.32552-0.22000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 20s 306ms/step - loss: 2.1537 - categorical_accuracy: 0.2090 - val_loss: 2.1431 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-2.15368-0.20896-2.14307-0.30000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 2.0102 - categorical_accuracy: 0.2488 - val_loss: 2.5489 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-2.01022-0.24876-2.54888-0.20000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 23s 346ms/step - loss: 1.9522 - categorical_accuracy: 0.2338 - val_loss: 1.5994 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.95225-0.23383-1.59937-0.32000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 22s 329ms/step - loss: 1.9342 - categorical_accuracy: 0.2139 - val_loss: 1.9008 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.93418-0.21393-1.90079-0.18000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 23s 337ms/step - loss: 2.0635 - categorical_accuracy: 0.2040 - val_loss: 1.6613 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-2.06351-0.20398-1.66127-0.32000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 23s 344ms/step - loss: 1.9986 - categorical_accuracy: 0.2139 - val_loss: 1.5710 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.99857-0.21393-1.57102-0.30000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 24s 352ms/step - loss: 1.8293 - categorical_accuracy: 0.2587 - val_loss: 1.4574 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.82929-0.25871-1.45743-0.40000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 23s 336ms/step - loss: 1.9012 - categorical_accuracy: 0.2537 - val_loss: 1.7378 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.90118-0.25373-1.73783-0.32000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 22s 330ms/step - loss: 1.8681 - categorical_accuracy: 0.2388 - val_loss: 1.5425 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-1.86814-0.23881-1.54248-0.24000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 1.7448 - categorical_accuracy: 0.3134 - val_loss: 1.5924 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-1.74477-0.31343-1.59238-0.34000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 22s 325ms/step - loss: 1.7795 - categorical_accuracy: 0.2786 - val_loss: 1.4697 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-1.77953-0.27861-1.46965-0.34000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 22s 327ms/step - loss: 1.8661 - categorical_accuracy: 0.2488 - val_loss: 1.3339 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-1.86606-0.24876-1.33388-0.46000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 23s 338ms/step - loss: 1.8394 - categorical_accuracy: 0.2338 - val_loss: 1.4252 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-1.83942-0.23383-1.42516-0.40000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 23s 342ms/step - loss: 1.6682 - categorical_accuracy: 0.3333 - val_loss: 1.3752 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-1.66820-0.33333-1.37524-0.32000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 24s 358ms/step - loss: 1.9038 - categorical_accuracy: 0.2587 - val_loss: 1.4841 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-1.90378-0.25871-1.48413-0.34000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 21s 317ms/step - loss: 1.6596 - categorical_accuracy: 0.3134 - val_loss: 1.3139 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-1.65955-0.31343-1.31389-0.48000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 22s 332ms/step - loss: 1.7749 - categorical_accuracy: 0.2189 - val_loss: 1.3925 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-1.77491-0.21891-1.39246-0.38000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 21s 318ms/step - loss: 1.7317 - categorical_accuracy: 0.2687 - val_loss: 1.4053 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-1.73166-0.26866-1.40533-0.42000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.03125.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba54b3668>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 20\n",
    "model_e.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model F Experiment [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_29 (Conv3D)           (None, 30, 120, 120, 8)   224       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,317\n",
      "Trainable params: 3,667,077\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 1\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_f = Sequential()\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_f.add(Flatten())\n",
    "\n",
    "model_f.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_f.add(Dropout(0.5))\n",
    "\n",
    "model_f.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_f.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_f.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_f.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/30\n",
      " Project_data/val ; batch size = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 6.2486 - categorical_accuracy: 0.2723Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 80s 1s/step - loss: 6.1396 - categorical_accuracy: 0.2736 - val_loss: 1.3060 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-6.17850-0.27300-1.30603-0.51000.h5\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 2.7373 - categorical_accuracy: 0.2886 - val_loss: 1.7598 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-2.73734-0.28856-1.75976-0.38000.h5\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 1.8585 - categorical_accuracy: 0.3035 - val_loss: 1.2220 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.85848-0.30348-1.22204-0.46000.h5\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 1.7889 - categorical_accuracy: 0.2687 - val_loss: 1.1331 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.78890-0.26866-1.13314-0.54000.h5\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 1.5743 - categorical_accuracy: 0.3234 - val_loss: 1.3668 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.57431-0.32338-1.36678-0.38000.h5\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 1.5423 - categorical_accuracy: 0.3532 - val_loss: 1.2560 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.54232-0.35323-1.25600-0.41000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 1.4034 - categorical_accuracy: 0.3980 - val_loss: 1.1945 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.40338-0.39801-1.19454-0.52000.h5\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 24s 365ms/step - loss: 1.3583 - categorical_accuracy: 0.4229 - val_loss: 1.1120 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.35828-0.42289-1.11198-0.56000.h5\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 1.3211 - categorical_accuracy: 0.3930 - val_loss: 1.1176 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.32115-0.39303-1.11763-0.56000.h5\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 25s 375ms/step - loss: 1.2986 - categorical_accuracy: 0.4726 - val_loss: 1.1060 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.29858-0.47264-1.10605-0.51000.h5\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 25s 378ms/step - loss: 1.2810 - categorical_accuracy: 0.4527 - val_loss: 1.0933 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-1.28095-0.45274-1.09332-0.55000.h5\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 26s 390ms/step - loss: 1.3506 - categorical_accuracy: 0.4527 - val_loss: 0.9966 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-1.35062-0.45274-0.99657-0.59000.h5\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 1.2283 - categorical_accuracy: 0.5075 - val_loss: 1.0424 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-1.22830-0.50746-1.04243-0.53000.h5\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 25s 377ms/step - loss: 1.3640 - categorical_accuracy: 0.4677 - val_loss: 0.9824 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-1.36396-0.46766-0.98237-0.64000.h5\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 1.2157 - categorical_accuracy: 0.4876 - val_loss: 1.0729 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-1.21571-0.48756-1.07293-0.57000.h5\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 25s 375ms/step - loss: 1.2461 - categorical_accuracy: 0.4925 - val_loss: 1.0136 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-1.24610-0.49254-1.01362-0.56000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 26s 389ms/step - loss: 1.1030 - categorical_accuracy: 0.5522 - val_loss: 0.9635 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-1.10301-0.55224-0.96352-0.57000.h5\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 1.0797 - categorical_accuracy: 0.5274 - val_loss: 0.9402 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-1.07968-0.52736-0.94024-0.61000.h5\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 27s 403ms/step - loss: 1.0960 - categorical_accuracy: 0.5124 - val_loss: 0.9821 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-1.09605-0.51244-0.98205-0.58000.h5\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 1.0236 - categorical_accuracy: 0.5672 - val_loss: 0.9905 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-1.02363-0.56716-0.99055-0.60000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 1.0258 - categorical_accuracy: 0.5871 - val_loss: 0.8638 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-03-3004_10_50.546452/model-00021-1.02575-0.58706-0.86384-0.65000.h5\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 25s 376ms/step - loss: 0.9067 - categorical_accuracy: 0.6617 - val_loss: 0.9179 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-03-3004_10_50.546452/model-00022-0.90672-0.66169-0.91793-0.60000.h5\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 26s 382ms/step - loss: 1.0455 - categorical_accuracy: 0.5473 - val_loss: 0.9299 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-03-3004_10_50.546452/model-00023-1.04550-0.54726-0.92988-0.59000.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 1.0226 - categorical_accuracy: 0.5970 - val_loss: 0.8937 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-03-3004_10_50.546452/model-00024-1.02264-0.59701-0.89371-0.63000.h5\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 26s 385ms/step - loss: 0.9450 - categorical_accuracy: 0.6219 - val_loss: 0.8369 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-03-3004_10_50.546452/model-00025-0.94500-0.62189-0.83689-0.63000.h5\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 0.9371 - categorical_accuracy: 0.5721 - val_loss: 0.8281 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-03-3004_10_50.546452/model-00026-0.93712-0.57214-0.82814-0.67000.h5\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 25s 379ms/step - loss: 0.8269 - categorical_accuracy: 0.6617 - val_loss: 0.8027 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-03-3004_10_50.546452/model-00027-0.82689-0.66169-0.80269-0.68000.h5\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 0.8793 - categorical_accuracy: 0.6318 - val_loss: 0.8066 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-03-3004_10_50.546452/model-00028-0.87934-0.63184-0.80657-0.70000.h5\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 26s 381ms/step - loss: 0.8362 - categorical_accuracy: 0.6816 - val_loss: 0.7797 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-03-3004_10_50.546452/model-00029-0.83622-0.68159-0.77970-0.72000.h5\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 25s 374ms/step - loss: 0.9040 - categorical_accuracy: 0.6070 - val_loss: 0.7861 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-03-3004_10_50.546452/model-00030-0.90395-0.60697-0.78608-0.67000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba586f8d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 30\n",
    "model_f.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model G Experiment [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_33 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_35 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_36 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 3\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_g = Sequential()\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_g.add(Flatten())\n",
    "\n",
    "model_g.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_g.add(Dropout(0.5))\n",
    "\n",
    "model_g.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_g.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_g.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_g.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 5.1344 - categorical_accuracy: 0.2938Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 87s 1s/step - loss: 5.0411 - categorical_accuracy: 0.2975 - val_loss: 3.1104 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-5.06684-0.29713-3.11036-0.32000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 2.5571 - categorical_accuracy: 0.3085 - val_loss: 2.5285 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-2.55714-0.30846-2.52854-0.25000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 28s 425ms/step - loss: 1.8454 - categorical_accuracy: 0.2687 - val_loss: 1.4425 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.84544-0.26866-1.44247-0.26000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 1.6922 - categorical_accuracy: 0.2886 - val_loss: 1.2505 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.69219-0.28856-1.25050-0.42000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 29s 433ms/step - loss: 1.6760 - categorical_accuracy: 0.3433 - val_loss: 1.3811 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.67602-0.34328-1.38105-0.42000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 29s 437ms/step - loss: 1.4814 - categorical_accuracy: 0.3781 - val_loss: 1.2942 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.48141-0.37811-1.29417-0.41000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 1.4462 - categorical_accuracy: 0.3483 - val_loss: 1.2774 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.44616-0.34826-1.27735-0.42000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 1.3412 - categorical_accuracy: 0.4478 - val_loss: 1.0824 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.34121-0.44776-1.08239-0.53000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 28s 424ms/step - loss: 1.2993 - categorical_accuracy: 0.4229 - val_loss: 1.2205 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.29928-0.42289-1.22048-0.39000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 1.2878 - categorical_accuracy: 0.3980 - val_loss: 0.9683 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.28776-0.39801-0.96833-0.61000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba2d0a780>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_g.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model H Experiment [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_37 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_38 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_39 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_40 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 3\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_h = Sequential()\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_h.add(Flatten())\n",
    "\n",
    "model_h.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "\n",
    "model_h.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_h.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_h.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_h.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path = Epoch 1/10 Project_data/train ; batch size = 10\n",
      "\n",
      " Project_data/val ; batch size = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 6.9439 - categorical_accuracy: 0.2708Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 87s 1s/step - loss: 6.7959 - categorical_accuracy: 0.2672 - val_loss: 5.9936 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-6.83865-0.26998-5.99359-0.25000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 25s 372ms/step - loss: 2.8407 - categorical_accuracy: 0.2836 - val_loss: 6.7763 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-2.84070-0.28358-6.77632-0.24000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 1.9889 - categorical_accuracy: 0.3035 - val_loss: 1.3144 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.98886-0.30348-1.31438-0.42000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 27s 400ms/step - loss: 1.7232 - categorical_accuracy: 0.3184 - val_loss: 1.7817 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.72317-0.31841-1.78170-0.31000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 29s 428ms/step - loss: 1.6201 - categorical_accuracy: 0.3582 - val_loss: 1.2711 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.62007-0.35821-1.27105-0.37000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 1.5317 - categorical_accuracy: 0.3234 - val_loss: 1.7303 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.53175-0.32338-1.73031-0.29000.h5\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 1.4544 - categorical_accuracy: 0.3831 - val_loss: 1.6615 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.45437-0.38308-1.66148-0.29000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 1.4113 - categorical_accuracy: 0.3632 - val_loss: 1.4185 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.41131-0.36318-1.41855-0.33000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 26s 386ms/step - loss: 1.3455 - categorical_accuracy: 0.4229 - val_loss: 1.0235 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.34551-0.42289-1.02346-0.51000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 1.2090 - categorical_accuracy: 0.4975 - val_loss: 1.0398 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.20901-0.49751-1.03985-0.52000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba16a9dd8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_h.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model I Experiment [12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_41 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_31 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_42 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_32 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_33 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_34 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,493\n",
      "Trainable params: 3,667,381\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 3\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_i = Sequential()\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_i.add(BatchNormalization())\n",
    "model_i.add(Activation('relu'))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_i.add(BatchNormalization())\n",
    "model_i.add(Activation('relu'))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_i.add(BatchNormalization())\n",
    "model_i.add(Activation('relu'))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_i.add(Activation('relu'))\n",
    "model_i.add(Dropout(0.25))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_i.add(Flatten())\n",
    "\n",
    "model_i.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_i.add(Dropout(0.5))\n",
    "\n",
    "model_i.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_i.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_i.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_i.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 1.8883 - categorical_accuracy: 0.3077Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 84s 1s/step - loss: 1.8747 - categorical_accuracy: 0.3109 - val_loss: 1.4121 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-1.87965-0.31071-1.41214-0.27000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 24s 360ms/step - loss: 1.5907 - categorical_accuracy: 0.3632 - val_loss: 1.3142 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-1.59074-0.36318-1.31420-0.36000.h5\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 1.5060 - categorical_accuracy: 0.3333 - val_loss: 1.2637 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.50596-0.33333-1.26374-0.49000.h5\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 1.4880 - categorical_accuracy: 0.3731 - val_loss: 1.2316 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.48798-0.37313-1.23159-0.52000.h5\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 1.2636 - categorical_accuracy: 0.4677 - val_loss: 1.6657 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.26356-0.46766-1.66572-0.36000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 28s 414ms/step - loss: 1.3810 - categorical_accuracy: 0.4627 - val_loss: 1.3486 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.38095-0.46269-1.34860-0.41000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 26s 387ms/step - loss: 1.0826 - categorical_accuracy: 0.6070 - val_loss: 1.0242 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.08260-0.60697-1.02418-0.59000.h5\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 27s 398ms/step - loss: 1.0157 - categorical_accuracy: 0.6119 - val_loss: 0.8997 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.01573-0.61194-0.89975-0.66000.h5\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 26s 394ms/step - loss: 0.8844 - categorical_accuracy: 0.6219 - val_loss: 0.8950 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.88436-0.62189-0.89501-0.64000.h5\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 0.8693 - categorical_accuracy: 0.6468 - val_loss: 0.7932 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.86931-0.64677-0.79323-0.74000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba48ac5c0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_i.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model I Experiment [13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(30,120,120,3)\n",
    "\n",
    "# Define model\n",
    "model_final = Sequential()\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_final.add(BatchNormalization())\n",
    "model_final.add(Activation('relu'))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_final.add(BatchNormalization())\n",
    "model_final.add(Activation('relu'))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_final.add(BatchNormalization())\n",
    "model_final.add(Activation('relu'))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_final.add(Activation('relu'))\n",
    "model_final.add(Dropout(0.25))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_final.add(Flatten())\n",
    "\n",
    "model_final.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_final.add(Dropout(0.5))\n",
    "\n",
    "model_final.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_final.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_final.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_45 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_35 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_46 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_36 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_47 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_37 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_48 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_38 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = keras.optimizers.Adam() #write your optimizer\n",
    "model_final.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/67 [============================>.] - ETA: 2s - loss: 1.9641 - categorical_accuracy: 0.2369Batch:  67 Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 86s 1s/step - loss: 1.9500 - categorical_accuracy: 0.2442 - val_loss: 1.5218 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-1.95611-0.23982-1.52179-0.28000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 26s 392ms/step - loss: 1.5787 - categorical_accuracy: 0.3234 - val_loss: 1.4428 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-1.57865-0.32338-1.44285-0.48000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 1.5158 - categorical_accuracy: 0.3184 - val_loss: 1.2818 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-1.51584-0.31841-1.28182-0.47000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 1.5968 - categorical_accuracy: 0.2935 - val_loss: 1.5306 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.59683-0.29353-1.53058-0.39000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 28s 421ms/step - loss: 1.5469 - categorical_accuracy: 0.2587 - val_loss: 1.4613 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-1.54687-0.25871-1.46126-0.40000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 26s 383ms/step - loss: 1.4433 - categorical_accuracy: 0.3483 - val_loss: 1.2961 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-1.44325-0.34826-1.29607-0.40000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 1.4176 - categorical_accuracy: 0.3483 - val_loss: 1.3930 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-1.41759-0.34826-1.39304-0.41000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 1.3346 - categorical_accuracy: 0.4428 - val_loss: 1.2922 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-1.33457-0.44279-1.29224-0.42000.h5\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 29s 436ms/step - loss: 1.3672 - categorical_accuracy: 0.3781 - val_loss: 1.2306 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-1.36720-0.37811-1.23060-0.47000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 27s 407ms/step - loss: 1.2879 - categorical_accuracy: 0.3980 - val_loss: 1.1990 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-1.28792-0.39801-1.19901-0.48000.h5\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 1.2841 - categorical_accuracy: 0.4129 - val_loss: 1.2251 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-1.28415-0.41294-1.22512-0.51000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 1.1951 - categorical_accuracy: 0.4975 - val_loss: 1.1117 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-1.19512-0.49751-1.11166-0.59000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 26s 384ms/step - loss: 1.2431 - categorical_accuracy: 0.4925 - val_loss: 1.1345 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-1.24311-0.49254-1.13449-0.52000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 1.2241 - categorical_accuracy: 0.4527 - val_loss: 1.0728 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-1.22410-0.45274-1.07284-0.64000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 29s 433ms/step - loss: 1.1057 - categorical_accuracy: 0.5473 - val_loss: 1.0124 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-1.10567-0.54726-1.01237-0.63000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 27s 396ms/step - loss: 1.2050 - categorical_accuracy: 0.4726 - val_loss: 1.1326 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-1.20501-0.47264-1.13264-0.57000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 1.0745 - categorical_accuracy: 0.4876 - val_loss: 1.0111 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-1.07446-0.48756-1.01111-0.61000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 1.1392 - categorical_accuracy: 0.5174 - val_loss: 1.0259 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-1.13924-0.51741-1.02595-0.52000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 28s 421ms/step - loss: 1.1167 - categorical_accuracy: 0.4876 - val_loss: 0.9912 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-1.11666-0.48756-0.99117-0.55000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 26s 391ms/step - loss: 1.0227 - categorical_accuracy: 0.5920 - val_loss: 0.9733 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-1.02274-0.59204-0.97330-0.61000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b9ef622e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 30s 446ms/step - loss: 1.0592 - categorical_accuracy: 0.5821 - val_loss: 0.9573 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-1.05921-0.58209-0.95726-0.58000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 27s 408ms/step - loss: 0.9937 - categorical_accuracy: 0.5821 - val_loss: 0.8887 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.99368-0.58209-0.88873-0.61000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 29s 426ms/step - loss: 0.9342 - categorical_accuracy: 0.6318 - val_loss: 0.9415 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.93425-0.63184-0.94147-0.57000.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 27s 401ms/step - loss: 1.0250 - categorical_accuracy: 0.6020 - val_loss: 0.9950 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-1.02496-0.60199-0.99499-0.55000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 0.9069 - categorical_accuracy: 0.6020 - val_loss: 0.8666 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.90694-0.60199-0.86655-0.64000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 28s 424ms/step - loss: 0.8165 - categorical_accuracy: 0.6716 - val_loss: 0.8247 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.81648-0.67164-0.82468-0.64000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 29s 428ms/step - loss: 0.8446 - categorical_accuracy: 0.6368 - val_loss: 0.9021 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.84460-0.63682-0.90214-0.61000.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 26s 395ms/step - loss: 0.8587 - categorical_accuracy: 0.6866 - val_loss: 0.8366 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.85869-0.68657-0.83662-0.65000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 28s 417ms/step - loss: 0.8425 - categorical_accuracy: 0.6418 - val_loss: 0.8622 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.84253-0.64179-0.86221-0.68000.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 0.7847 - categorical_accuracy: 0.6766 - val_loss: 0.8368 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.78470-0.67662-0.83683-0.67000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 28s 418ms/step - loss: 0.8295 - categorical_accuracy: 0.6816 - val_loss: 0.8643 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-0.82948-0.68159-0.86427-0.62000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 29s 427ms/step - loss: 0.7465 - categorical_accuracy: 0.7164 - val_loss: 0.8096 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-0.74645-0.71642-0.80960-0.70000.h5\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 0.7070 - categorical_accuracy: 0.7363 - val_loss: 0.8452 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-0.70703-0.73632-0.84518-0.65000.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 28s 411ms/step - loss: 0.7950 - categorical_accuracy: 0.7015 - val_loss: 0.8123 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-0.79502-0.70149-0.81233-0.69000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 28s 411ms/step - loss: 0.7049 - categorical_accuracy: 0.7114 - val_loss: 0.8003 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-0.70487-0.71144-0.80035-0.68000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 29s 428ms/step - loss: 0.7134 - categorical_accuracy: 0.6866 - val_loss: 0.8486 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-0.71339-0.68657-0.84856-0.65000.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 0.7205 - categorical_accuracy: 0.7065 - val_loss: 0.7790 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-0.72047-0.70647-0.77903-0.72000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 29s 433ms/step - loss: 0.7812 - categorical_accuracy: 0.7065 - val_loss: 0.8344 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-0.78123-0.70647-0.83443-0.67000.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 28s 419ms/step - loss: 0.6718 - categorical_accuracy: 0.7164 - val_loss: 0.7873 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-0.67178-0.71642-0.78725-0.70000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 29s 430ms/step - loss: 0.7656 - categorical_accuracy: 0.6816 - val_loss: 0.8486 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-0.76558-0.68159-0.84864-0.68000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b9ef62e10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 64\n",
      "Source path =  Project_data/train ; batch size = 64\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  2 Index: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/67 [..............................] - ETA: 10:44 - loss: 0.6946 - categorical_accuracy: 0.7578Batch:  3 Index: 36\n",
      " 5/67 [=>............................] - ETA: 9:46 - loss: 0.6738 - categorical_accuracy: 0.7469Batch:  4 Index: 28\n",
      " 9/67 [===>..........................] - ETA: 8:31 - loss: 0.6741 - categorical_accuracy: 0.7431Batch:  11 Index: 64\n",
      "38/67 [================>.............] - ETA: 2:04 - loss: 0.6705 - categorical_accuracy: 0.7385Batch:  29 Index: 23\n",
      "67/67 [==============================] - 238s 4s/step - loss: 0.6690 - categorical_accuracy: 0.7352 - val_loss: 0.7883 - val_categorical_accuracy: 0.6994\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.67080-0.73790-0.78829-0.69937.h5\n",
      "Epoch 2/20\n",
      " 5/67 [=>............................] - ETA: 1:41 - loss: 0.6731 - categorical_accuracy: 0.6842Batch:  7 Index: 16\n",
      " 6/67 [=>............................] - ETA: 1:53 - loss: 0.6676 - categorical_accuracy: 0.6930Batch:  35 Index: 19\n",
      "67/67 [==============================] - 139s 2s/step - loss: 0.6744 - categorical_accuracy: 0.7352 - val_loss: 0.8868 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.67426-0.73461-0.88681-0.65000.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.6565 - categorical_accuracy: 0.7489 - val_loss: 0.7220 - val_categorical_accuracy: 0.7750\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.65649-0.74890-0.72201-0.77500.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 142s 2s/step - loss: 0.7149 - categorical_accuracy: 0.7173 - val_loss: 0.7106 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.71489-0.71730-0.71060-0.67500.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6914 - categorical_accuracy: 0.7322 - val_loss: 0.8338 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.69145-0.73222-0.83376-0.62500.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.6614 - categorical_accuracy: 0.7392 - val_loss: 0.8321 - val_categorical_accuracy: 0.7250\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.66136-0.73924-0.83207-0.72500.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 141s 2s/step - loss: 0.6556 - categorical_accuracy: 0.7322 - val_loss: 0.7726 - val_categorical_accuracy: 0.7750\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.65563-0.73222-0.77260-0.77500.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 138s 2s/step - loss: 0.6498 - categorical_accuracy: 0.7445 - val_loss: 0.7961 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.64979-0.74451-0.79606-0.70000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6471 - categorical_accuracy: 0.7542 - val_loss: 0.7700 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.64710-0.75417-0.77000-0.67500.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 139s 2s/step - loss: 0.6795 - categorical_accuracy: 0.7357 - val_loss: 0.7404 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.67950-0.73573-0.74035-0.67500.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6739 - categorical_accuracy: 0.7419 - val_loss: 0.7251 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-0.67387-0.74188-0.72510-0.75000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6691 - categorical_accuracy: 0.7278 - val_loss: 0.8098 - val_categorical_accuracy: 0.7250\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-0.66915-0.72783-0.80976-0.72500.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 141s 2s/step - loss: 0.6581 - categorical_accuracy: 0.7401 - val_loss: 0.8502 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-0.65809-0.74012-0.85019-0.62500.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 137s 2s/step - loss: 0.6881 - categorical_accuracy: 0.7331 - val_loss: 0.8408 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-0.68809-0.73310-0.84083-0.65000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6430 - categorical_accuracy: 0.7480 - val_loss: 0.7387 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-0.64300-0.74802-0.73870-0.80000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6548 - categorical_accuracy: 0.7428 - val_loss: 0.7982 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-0.65478-0.74276-0.79816-0.65000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6598 - categorical_accuracy: 0.7436 - val_loss: 0.8406 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-0.65975-0.74363-0.84060-0.65000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 139s 2s/step - loss: 0.6592 - categorical_accuracy: 0.7384 - val_loss: 0.8029 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-0.65924-0.73837-0.80292-0.65000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 139s 2s/step - loss: 0.6757 - categorical_accuracy: 0.7419 - val_loss: 0.7860 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-0.67568-0.74188-0.78600-0.75000.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.6617 - categorical_accuracy: 0.7515 - val_loss: 0.8155 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-0.66167-0.75154-0.81548-0.62500.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b9dea5390>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "\n",
    "\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Source path =  Project_data/train ; batch size = Epoch 1/20\n",
      "Project_data/val ; batch size = 40\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/67 [..............................] - ETA: 6:41 - loss: 0.6649 - categorical_accuracy: 0.7500Batch:  3 Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/67 [=====>........................] - ETA: 4:38 - loss: 0.6520 - categorical_accuracy: 0.7567Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:25 - loss: 0.6559 - categorical_accuracy: 0.7578Batch:  29 Index: 23\n",
      "67/67 [==============================] - 223s 3s/step - loss: 0.6568 - categorical_accuracy: 0.7573 - val_loss: 0.7997 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3004_10_50.546452/model-00001-0.65485-0.75768-0.79972-0.68333.h5\n",
      "Epoch 2/20\n",
      "12/67 [====>.........................] - ETA: 2:13 - loss: 0.6437 - categorical_accuracy: 0.7368Batch:  35 Index: 19\n",
      "67/67 [==============================] - 148s 2s/step - loss: 0.6543 - categorical_accuracy: 0.7437 - val_loss: 0.8109 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3004_10_50.546452/model-00002-0.65410-0.74335-0.81092-0.67500.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6292 - categorical_accuracy: 0.7621 - val_loss: 0.8023 - val_categorical_accuracy: 0.6950\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3004_10_50.546452/model-00003-0.62919-0.76207-0.80232-0.69500.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 147s 2s/step - loss: 0.6487 - categorical_accuracy: 0.7542 - val_loss: 0.7724 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3004_10_50.546452/model-00004-0.64869-0.75417-0.77242-0.71000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.6909 - categorical_accuracy: 0.7226 - val_loss: 0.8099 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3004_10_50.546452/model-00005-0.69088-0.72256-0.80991-0.65000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 146s 2s/step - loss: 0.6625 - categorical_accuracy: 0.7401 - val_loss: 0.7942 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3004_10_50.546452/model-00006-0.66249-0.74012-0.79417-0.72000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6563 - categorical_accuracy: 0.7428 - val_loss: 0.8007 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3004_10_50.546452/model-00007-0.65635-0.74276-0.80071-0.67500.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.6887 - categorical_accuracy: 0.7234 - val_loss: 0.7921 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3004_10_50.546452/model-00008-0.68873-0.72344-0.79211-0.71000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.6466 - categorical_accuracy: 0.7410 - val_loss: 0.7734 - val_categorical_accuracy: 0.7050\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3004_10_50.546452/model-00009-0.64664-0.74100-0.77339-0.70500.h5\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 147s 2s/step - loss: 0.6190 - categorical_accuracy: 0.7594 - val_loss: 0.8010 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3004_10_50.546452/model-00010-0.61898-0.75944-0.80103-0.68000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6722 - categorical_accuracy: 0.7375 - val_loss: 0.7868 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3004_10_50.546452/model-00011-0.67225-0.73749-0.78678-0.69000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 146s 2s/step - loss: 0.6730 - categorical_accuracy: 0.7401 - val_loss: 0.8295 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3004_10_50.546452/model-00012-0.67305-0.74012-0.82952-0.68000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 146s 2s/step - loss: 0.6689 - categorical_accuracy: 0.7375 - val_loss: 0.8080 - val_categorical_accuracy: 0.6850\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3004_10_50.546452/model-00013-0.66891-0.73749-0.80800-0.68500.h5\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6808 - categorical_accuracy: 0.7349 - val_loss: 0.7454 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3004_10_50.546452/model-00014-0.68079-0.73486-0.74541-0.72000.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 146s 2s/step - loss: 0.6938 - categorical_accuracy: 0.7199 - val_loss: 0.8030 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3004_10_50.546452/model-00015-0.69376-0.71993-0.80296-0.70000.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6514 - categorical_accuracy: 0.7471 - val_loss: 0.7917 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3004_10_50.546452/model-00016-0.65140-0.74715-0.79174-0.69000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6717 - categorical_accuracy: 0.7349 - val_loss: 0.8278 - val_categorical_accuracy: 0.6750\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3004_10_50.546452/model-00017-0.67173-0.73486-0.82777-0.67500.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.6770 - categorical_accuracy: 0.7313 - val_loss: 0.8173 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3004_10_50.546452/model-00018-0.67703-0.73134-0.81728-0.67000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.6816 - categorical_accuracy: 0.7278 - val_loss: 0.7583 - val_categorical_accuracy: 0.7150\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3004_10_50.546452/model-00019-0.68158-0.72783-0.75830-0.71500.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.6818 - categorical_accuracy: 0.7217 - val_loss: 0.8364 - val_categorical_accuracy: 0.6650\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3004_10_50.546452/model-00020-0.68176-0.72169-0.83635-0.66500.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b9db086a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "\n",
    "\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder='Project_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model II Experiment [14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    def initialize_path(self,project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path =  project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "          \n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx): \n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "            \n",
    "\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "                    \n",
    "                    #shifted = cv2.warpAffine(image_resized, \n",
    "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
    "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCNN1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        #model.add(TimeDistributed(Conv2D(512, (2, 2) , padding='valid', activation='relu')))\n",
    "       # model.add(TimeDistributed(BatchNormalization()))\n",
    "       # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_17 (TimeDis (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 18, 7, 7, 256)     295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 18, 7, 7, 256)     1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 18, 3, 3, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 18, 2304)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               1245696   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,657,445\n",
      "Trainable params: 1,656,453\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn1=RNNCNN1()\n",
    "rnn_cnn1.initialize_path(project_folder)\n",
    "rnn_cnn1.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn1.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
    "rnn_cnn1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1657445\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 201s 6s/step - loss: 1.4109 - categorical_accuracy: 0.3819 - val_loss: 1.2195 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3010_24_42.905043/model-00001-1.41795-0.38311-1.21946-0.49000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 97s 3s/step - loss: 1.1497 - categorical_accuracy: 0.5166 - val_loss: 1.6751 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3010_24_42.905043/model-00002-1.15164-0.52112-1.67507-0.37000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.9940 - categorical_accuracy: 0.5931 - val_loss: 1.3843 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3010_24_42.905043/model-00003-0.99651-0.59955-1.38433-0.46000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.8663 - categorical_accuracy: 0.6667 - val_loss: 1.0229 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3010_24_42.905043/model-00004-0.86620-0.66667-1.02294-0.62000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.8361 - categorical_accuracy: 0.6711 - val_loss: 0.7635 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3010_24_42.905043/model-00005-0.80189-0.67949-0.76348-0.70000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.7876 - categorical_accuracy: 0.6957 - val_loss: 1.3161 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3010_24_42.905043/model-00006-0.78101-0.70060-1.31607-0.49000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.7121 - categorical_accuracy: 0.7219 - val_loss: 1.4181 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3010_24_42.905043/model-00007-0.71983-0.71493-1.41808-0.45000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.5833 - categorical_accuracy: 0.7752 - val_loss: 2.6318 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3010_24_42.905043/model-00008-0.58784-0.77376-2.63178-0.27000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.5483 - categorical_accuracy: 0.8010 - val_loss: 1.1230 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3010_24_42.905043/model-00009-0.53753-0.80015-1.12299-0.54000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.5015 - categorical_accuracy: 0.8028 - val_loss: 0.9940 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3010_24_42.905043/model-00010-0.48233-0.81448-0.99399-0.68000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.3902 - categorical_accuracy: 0.8462 - val_loss: 0.6411 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3010_24_42.905043/model-00011-0.38427-0.85068-0.64113-0.75000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.3126 - categorical_accuracy: 0.8823 - val_loss: 0.5824 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3010_24_42.905043/model-00012-0.31686-0.87934-0.58238-0.77000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.2891 - categorical_accuracy: 0.9054 - val_loss: 0.5752 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3010_24_42.905043/model-00013-0.28840-0.90724-0.57518-0.79000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.3061 - categorical_accuracy: 0.8845 - val_loss: 0.5647 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3010_24_42.905043/model-00014-0.28591-0.89819-0.56470-0.81000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.2460 - categorical_accuracy: 0.9117 - val_loss: 0.5322 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3010_24_42.905043/model-00015-0.24966-0.90950-0.53216-0.78000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.2227 - categorical_accuracy: 0.9301 - val_loss: 0.5010 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3010_24_42.905043/model-00016-0.22235-0.92836-0.50100-0.80000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.2465 - categorical_accuracy: 0.9121 - val_loss: 0.4986 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3010_24_42.905043/model-00017-0.22765-0.92232-0.49856-0.82000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.1978 - categorical_accuracy: 0.9404 - val_loss: 0.6254 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3010_24_42.905043/model-00018-0.20176-0.93891-0.62541-0.74000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.1927 - categorical_accuracy: 0.9437 - val_loss: 0.4881 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3010_24_42.905043/model-00019-0.18470-0.94646-0.48806-0.81000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 0.1716 - categorical_accuracy: 0.9492 - val_loss: 0.5057 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3010_24_42.905043/model-00020-0.17427-0.94796-0.50573-0.84000.h5\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
    "history_model9=rnn_cnn1.train_model(rnn_cnn1_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_model9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model II Experiment [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilderMoreAugmentation(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    def initialize_path(self,project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path =  project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "          \n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx): \n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "            \n",
    "\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "                    \n",
    "                    M = cv2.getRotationMatrix2D((self.image_width//2,self.image_height//2),\n",
    "                                                np.random.randint(-10,10), 1.0)\n",
    "                    rotated = cv2.warpAffine(image_resized, M, (self.image_width, self.image_height))\n",
    "                    \n",
    "                    #shifted = cv2.warpAffine(image_resized, \n",
    "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
    "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (rotated[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (rotated[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (rotated[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCNN2(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(GRU(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_33 (TimeDis (None, 18, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 18, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 18, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 18, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 18, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 18, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 18, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 18, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 18, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 18, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 18, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 18, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 18, 6272)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               2457984   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,573,541\n",
      "Trainable params: 2,573,061\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn2=RNNCNN2()\n",
    "rnn_cnn2.initialize_path(project_folder)\n",
    "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
    "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2573541\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 107s 3s/step - loss: 1.5441 - categorical_accuracy: 0.3271 - val_loss: 1.2014 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3011_24_13.236891/model-00001-1.53674-0.33107-1.20136-0.57000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 1.1142 - categorical_accuracy: 0.5614 - val_loss: 1.1158 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3011_24_13.236891/model-00002-1.09968-0.56712-1.11585-0.52000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.9488 - categorical_accuracy: 0.6372 - val_loss: 0.9338 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3011_24_13.236891/model-00003-0.93808-0.64480-0.93376-0.68000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 102s 3s/step - loss: 0.7743 - categorical_accuracy: 0.7163 - val_loss: 0.8416 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3011_24_13.236891/model-00004-0.77642-0.71342-0.84157-0.69000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.6490 - categorical_accuracy: 0.7723 - val_loss: 0.8366 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3011_24_13.236891/model-00005-0.63672-0.77074-0.83661-0.67000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.5472 - categorical_accuracy: 0.8113 - val_loss: 0.7593 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3011_24_13.236891/model-00006-0.54158-0.81900-0.75930-0.73000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.4473 - categorical_accuracy: 0.8455 - val_loss: 0.7895 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3011_24_13.236891/model-00007-0.45130-0.84163-0.78954-0.70000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.3655 - categorical_accuracy: 0.8918 - val_loss: 0.7175 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3011_24_13.236891/model-00008-0.34337-0.89744-0.71755-0.76000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.3288 - categorical_accuracy: 0.9080 - val_loss: 0.7488 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3011_24_13.236891/model-00009-0.33163-0.90573-0.74880-0.75000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.2588 - categorical_accuracy: 0.9242 - val_loss: 0.7368 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3011_24_13.236891/model-00010-0.25977-0.92232-0.73678-0.79000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.2044 - categorical_accuracy: 0.9455 - val_loss: 0.6956 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3011_24_13.236891/model-00011-0.20653-0.94419-0.69556-0.78000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 102s 3s/step - loss: 0.1738 - categorical_accuracy: 0.9581 - val_loss: 0.6899 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3011_24_13.236891/model-00012-0.17681-0.95701-0.68987-0.76000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 102s 3s/step - loss: 0.1827 - categorical_accuracy: 0.9422 - val_loss: 0.7267 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3011_24_13.236891/model-00013-0.16568-0.95324-0.72665-0.78000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.1778 - categorical_accuracy: 0.9441 - val_loss: 0.6887 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3011_24_13.236891/model-00014-0.17970-0.94268-0.68866-0.81000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.1360 - categorical_accuracy: 0.9581 - val_loss: 0.7643 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3011_24_13.236891/model-00015-0.13839-0.95701-0.76426-0.77000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.0901 - categorical_accuracy: 0.9845 - val_loss: 0.7623 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3011_24_13.236891/model-00016-0.09115-0.98416-0.76235-0.76000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 102s 3s/step - loss: 0.0776 - categorical_accuracy: 0.9805 - val_loss: 0.7808 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3011_24_13.236891/model-00017-0.07251-0.98416-0.78083-0.78000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 102s 3s/step - loss: 0.1095 - categorical_accuracy: 0.9698 - val_loss: 0.8350 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3011_24_13.236891/model-00018-0.10998-0.96908-0.83498-0.74000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.0581 - categorical_accuracy: 0.9912 - val_loss: 0.8704 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3011_24_13.236891/model-00019-0.05935-0.99095-0.87036-0.74000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 101s 3s/step - loss: 0.0761 - categorical_accuracy: 0.9746 - val_loss: 0.8359 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3011_24_13.236891/model-00020-0.06131-0.98643-0.83589-0.76000.h5\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
    "history_model17=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_model17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model II Experiment [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class RNNCNN_TL(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        \n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_46 (TimeDis (None, 16, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_47 (TimeDis (None, 16, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               590336    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,840,453\n",
      "Trainable params: 609,541\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn_tl=RNNCNN_TL()\n",
    "rnn_cnn_tl.initialize_path(project_folder)\n",
    "rnn_cnn_tl.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn_tl.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
    "rnn_cnn_tl_model=rnn_cnn_tl.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3840453\n",
      "Epoch 1/20\n",
      "133/133 [==============================] - 159s 1s/step - loss: 1.4646 - categorical_accuracy: 0.3607 - val_loss: 1.3475 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3012_00_57.780855/model-00001-1.46489-0.36124-1.34751-0.46000.h5\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 86s 647ms/step - loss: 1.2388 - categorical_accuracy: 0.4857 - val_loss: 1.0954 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3012_00_57.780855/model-00002-1.23762-0.48718-1.09537-0.61000.h5\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 88s 658ms/step - loss: 1.0489 - categorical_accuracy: 0.5965 - val_loss: 1.1694 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3012_00_57.780855/model-00003-1.04566-0.59729-1.16943-0.53000.h5\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 87s 656ms/step - loss: 0.8780 - categorical_accuracy: 0.6572 - val_loss: 1.2274 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3012_00_57.780855/model-00004-0.87175-0.65913-1.22743-0.57000.h5\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 87s 657ms/step - loss: 0.8154 - categorical_accuracy: 0.6870 - val_loss: 0.9098 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3012_00_57.780855/model-00005-0.81517-0.68703-0.90984-0.67000.h5\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 88s 659ms/step - loss: 0.7878 - categorical_accuracy: 0.6832 - val_loss: 1.1532 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3012_00_57.780855/model-00006-0.78726-0.68326-1.15323-0.50000.h5\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 88s 660ms/step - loss: 0.7007 - categorical_accuracy: 0.7155 - val_loss: 1.2278 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3012_00_57.780855/model-00007-0.70131-0.71569-1.22782-0.52000.h5\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 88s 660ms/step - loss: 0.6962 - categorical_accuracy: 0.7353 - val_loss: 1.2588 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3012_00_57.780855/model-00008-0.69793-0.73454-1.25875-0.55000.h5\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 88s 659ms/step - loss: 0.6065 - categorical_accuracy: 0.7566 - val_loss: 1.4397 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3012_00_57.780855/model-00009-0.60686-0.75641-1.43965-0.51000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 86s 650ms/step - loss: 0.4890 - categorical_accuracy: 0.8201 - val_loss: 1.3624 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3012_00_57.780855/model-00010-0.48769-0.82051-1.36244-0.53000.h5\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 87s 653ms/step - loss: 0.4620 - categorical_accuracy: 0.8333 - val_loss: 1.3464 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3012_00_57.780855/model-00011-0.46242-0.83333-1.34644-0.52000.h5\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - 88s 663ms/step - loss: 0.4265 - categorical_accuracy: 0.8566 - val_loss: 1.2695 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3012_00_57.780855/model-00012-0.42578-0.85671-1.26950-0.53000.h5\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 87s 653ms/step - loss: 0.3893 - categorical_accuracy: 0.8609 - val_loss: 1.1856 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3012_00_57.780855/model-00013-0.39015-0.86048-1.18559-0.53000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 89s 669ms/step - loss: 0.4132 - categorical_accuracy: 0.8579 - val_loss: 1.1751 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3012_00_57.780855/model-00014-0.41422-0.85747-1.17507-0.55000.h5\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 89s 668ms/step - loss: 0.3996 - categorical_accuracy: 0.8506 - val_loss: 1.1842 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3012_00_57.780855/model-00015-0.39881-0.85068-1.18421-0.54000.h5\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 88s 664ms/step - loss: 0.3757 - categorical_accuracy: 0.8599 - val_loss: 1.1924 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3012_00_57.780855/model-00016-0.37441-0.86048-1.19241-0.54000.h5\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 88s 665ms/step - loss: 0.3691 - categorical_accuracy: 0.8717 - val_loss: 1.2089 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3012_00_57.780855/model-00017-0.36500-0.87330-1.20894-0.55000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 89s 668ms/step - loss: 0.3694 - categorical_accuracy: 0.8684 - val_loss: 1.2060 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3012_00_57.780855/model-00018-0.37003-0.86802-1.20599-0.55000.h5\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 89s 670ms/step - loss: 0.3300 - categorical_accuracy: 0.8827 - val_loss: 1.2096 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3012_00_57.780855/model-00019-0.33089-0.88235-1.20964-0.54000.h5\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - 88s 663ms/step - loss: 0.3664 - categorical_accuracy: 0.8662 - val_loss: 1.1964 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3012_00_57.780855/model-00020-0.36716-0.86576-1.19640-0.55000.h5\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn_tl_model.count_params())\n",
    "history_model18=rnn_cnn_tl.train_model(rnn_cnn_tl_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_model18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model II Experiment [17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class RNNCNN_TL2(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,gru_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    " \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(gru_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_50 (TimeDis (None, 16, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_51 (TimeDis (None, 16, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_52 (TimeDis (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_53 (TimeDis (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               442752    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,692,869\n",
      "Trainable params: 3,668,933\n",
      "Non-trainable params: 23,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn_tl2=RNNCNN_TL2()\n",
    "rnn_cnn_tl2.initialize_path(project_folder)\n",
    "rnn_cnn_tl2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn_tl2.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
    "rnn_cnn_tl2_model=rnn_cnn_tl2.define_model(gru_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3692869\n",
      "Epoch 1/20\n",
      "133/133 [==============================] - 105s 791ms/step - loss: 1.3064 - categorical_accuracy: 0.4581 - val_loss: 0.8434 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-03-3012_42_10.536697/model-00001-1.30822-0.45701-0.84338-0.57000.h5\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 91s 683ms/step - loss: 0.8285 - categorical_accuracy: 0.6799 - val_loss: 0.6456 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-03-3012_42_10.536697/model-00002-0.82922-0.67949-0.64557-0.75000.h5\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 94s 706ms/step - loss: 0.5398 - categorical_accuracy: 0.8033 - val_loss: 0.4915 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-03-3012_42_10.536697/model-00003-0.53959-0.80317-0.49151-0.84000.h5\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 95s 712ms/step - loss: 0.4169 - categorical_accuracy: 0.8499 - val_loss: 0.5176 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-03-3012_42_10.536697/model-00004-0.41530-0.85143-0.51758-0.81000.h5\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 97s 733ms/step - loss: 0.3665 - categorical_accuracy: 0.8659 - val_loss: 0.5044 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-03-3012_42_10.536697/model-00005-0.36541-0.86652-0.50440-0.77000.h5\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 94s 706ms/step - loss: 0.3049 - categorical_accuracy: 0.8910 - val_loss: 1.1231 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-03-3012_42_10.536697/model-00006-0.30572-0.89065-1.12308-0.75000.h5\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 95s 711ms/step - loss: 0.3487 - categorical_accuracy: 0.8804 - val_loss: 0.3921 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-03-3012_42_10.536697/model-00007-0.34959-0.88009-0.39209-0.86000.h5\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 97s 732ms/step - loss: 0.2369 - categorical_accuracy: 0.9145 - val_loss: 0.2396 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-03-3012_42_10.536697/model-00008-0.23274-0.91629-0.23965-0.92000.h5\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 94s 705ms/step - loss: 0.2475 - categorical_accuracy: 0.9211 - val_loss: 0.3609 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-03-3012_42_10.536697/model-00009-0.24797-0.92081-0.36091-0.85000.h5\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 95s 717ms/step - loss: 0.1529 - categorical_accuracy: 0.9504 - val_loss: 0.5353 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-03-3012_42_10.536697/model-00010-0.15327-0.95023-0.53529-0.82000.h5\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 94s 708ms/step - loss: 0.1915 - categorical_accuracy: 0.9421 - val_loss: 0.6538 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-03-3012_42_10.536697/model-00011-0.19189-0.94193-0.65379-0.80000.h5\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - 96s 724ms/step - loss: 0.2273 - categorical_accuracy: 0.9213 - val_loss: 1.3261 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-03-3012_42_10.536697/model-00012-0.22718-0.92157-1.32609-0.74000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 94s 704ms/step - loss: 0.2333 - categorical_accuracy: 0.9198 - val_loss: 0.3255 - val_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-03-3012_42_10.536697/model-00013-0.23347-0.92006-0.32553-0.89000.h5\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 97s 731ms/step - loss: 0.0951 - categorical_accuracy: 0.9669 - val_loss: 0.1856 - val_categorical_accuracy: 0.9300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-03-3012_42_10.536697/model-00014-0.09519-0.96682-0.18557-0.93000.h5\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 95s 716ms/step - loss: 0.0793 - categorical_accuracy: 0.9774 - val_loss: 0.1613 - val_categorical_accuracy: 0.9500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-03-3012_42_10.536697/model-00015-0.07950-0.97738-0.16130-0.95000.h5\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 98s 734ms/step - loss: 0.0726 - categorical_accuracy: 0.9774 - val_loss: 0.1304 - val_categorical_accuracy: 0.9500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-03-3012_42_10.536697/model-00016-0.07251-0.97738-0.13038-0.95000.h5\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 95s 712ms/step - loss: 0.0449 - categorical_accuracy: 0.9875 - val_loss: 0.1242 - val_categorical_accuracy: 0.9600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-03-3012_42_10.536697/model-00017-0.04348-0.98793-0.12423-0.96000.h5\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 97s 730ms/step - loss: 0.0448 - categorical_accuracy: 0.9857 - val_loss: 0.1466 - val_categorical_accuracy: 0.9600\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-03-3012_42_10.536697/model-00018-0.04496-0.98567-0.14661-0.96000.h5\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 95s 712ms/step - loss: 0.0398 - categorical_accuracy: 0.9880 - val_loss: 0.1234 - val_categorical_accuracy: 0.9600\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-03-3012_42_10.536697/model-00019-0.03991-0.98793-0.12340-0.96000.h5\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - 97s 732ms/step - loss: 0.0305 - categorical_accuracy: 0.9887 - val_loss: 0.1248 - val_categorical_accuracy: 0.9400\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-03-3012_42_10.536697/model-00020-0.03050-0.98869-0.12485-0.94000.h5\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", rnn_cnn_tl2_model.count_params())\n",
    "history_model19=rnn_cnn_tl2.train_model(rnn_cnn_tl2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_model19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model II from experiment 17 (name: \"history_model19\") is the final selected model with training accuracy of ~99% and validation accuracy of 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
